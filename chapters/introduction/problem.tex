Every year new topics appear on the agenda of researchers and scientists, and all over the world research teams dedicate themselves publicly or privately to the most varied problems. The same research may be carried out by different organisations, which, with different resources and ways of working, produce huge volumes of data and make subjective analyses of them. 

This reality led to the emergence of the problem of how the management of the work produced should be carried out and, with this, generated the question of the need for mechanisms and systems that allow the way of working to be universalised \citep{9}. Thus, the issue better known as scientific data management arose.

There are several known solutions to this problem, and the systems responsible for this management may or may not have research data as a priority, the important thing is to understand if the functionalities they support are the most useful in solving the problem. Basically, the choice of a solution depends on the particularities of the research of the promoting entities, so before choosing a system, it is necessary to define the aspects to be evaluated \citep{dong}.
  
Specifically, this dissertation will take as a case study the \gls{sail} project carried out by \gls{inesctec} on board the School-Ship Sagres, the object of study of the project being atmospheric electricity and climate change, and aims to develop a scientific observation platform to collect data on the ocean and atmosphere \citep{2}. This will allow us to have a concrete idea of what a system should provide for a specific research case.
 
Despite the significant growth of existing solutions in the market, most scientific institutions, especially those linked to universities, still have their own data repository. This is due to the fact that performance capacity is something to be considered, since unlimited fast access at any time requires a certain amount of computing power, particularly if there is the premise of growing the repository and with it the accesses to it \citep{6}. Therefore, it would be interesting to understand how a solution can be integrated into supercomputing and big data infrastructures, more specifically, with the help of the \gls{macc}, which is developing the installation of the new Portuguese supercomputer Deucalion at AvePark, in Caldas das Taipas, Guimar√£es. In this case, we have to consider that the data stored in the system to be developed should be accessible through compute servers. For example, a File System (FS) such as Lustre (an open source parallel FS that supports many requirements of \gls{hpc} simulation environments) should be used for its data storage in a seamless and transparent manner.
